{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e8d229",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Face Detection Evaluation\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook evaluates different face detection models and their performance on classroom video data.\\n\",\n",
    "    \"\\n\",\n",
    "    \"## Models to Test:\\n\",\n",
    "    \"- OpenCV Haar Cascade\\n\",\n",
    "    \"- MTCNN\\n\",\n",
    "    \"- RetinaFace\\n\",\n",
    "    \"- YOLO-based face detection\\n\",\n",
    "    \"\\n\",\n",
    "    \"## Metrics:\\n\",\n",
    "    \"- Detection accuracy\\n\",\n",
    "    \"- Processing speed (FPS)\\n\",\n",
    "    \"- False positive/negative rates\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import sys\\n\",\n",
    "    \"sys.path.append('../src')\\n\",\n",
    "    \"\\n\",\n",
    "    \"import cv2\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import time\\n\",\n",
    "    \"from pathlib import Path\\n\",\n",
    "    \"import json\\n\",\n",
    "    \"\\n\",\n",
    "    \"from config import Config\\n\",\n",
    "    \"from detection.face_tracker import FaceTracker\\n\",\n",
    "    \"from utils.video_utils import VideoProcessor\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Load configuration\\n\",\n",
    "    \"config = Config()\\n\",\n",
    "    \"video_processor = VideoProcessor(config)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Test video path\\n\",\n",
    "    \"video_path = \\\"../data/raw_videos/sample_classroom.mp4\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Configuration loaded\\\")\\n\",\n",
    "    \"print(f\\\"Video path: {video_path}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Model Comparison\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def evaluate_detection_model(model_name, video_path, max_frames=100):\\n\",\n",
    "    \"    \\\"\\\"\\\"Evaluate a face detection model on video data.\\\"\\\"\\\"\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Set model in config\\n\",\n",
    "    \"    config.set('face_detection.model', model_name)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Initialize tracker\\n\",\n",
    "    \"    tracker = FaceTracker(config)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Process video\\n\",\n",
    "    \"    cap = cv2.VideoCapture(video_path)\\n\",\n",
    "    \"    if not cap.isOpened():\\n\",\n",
    "    \"        print(f\\\"Failed to open video: {video_path}\\\")\\n\",\n",
    "    \"        return None\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    detections = []\\n\",\n",
    "    \"    frame_count = 0\\n\",\n",
    "    \"    start_time = time.time()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    while frame_count < max_frames:\\n\",\n",
    "    \"        ret, frame = cap.read()\\n\",\n",
    "    \"        if not ret:\\n\",\n",
    "    \"            break\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Detect faces\\n\",\n",
    "    \"        frame_detections = tracker.detect_faces(frame)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Add frame info\\n\",\n",
    "    \"        for detection in frame_detections:\\n\",\n",
    "    \"            detection['frame_idx'] = frame_count\\n\",\n",
    "    \"            detection['model'] = model_name\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        detections.extend(frame_detections)\\n\",\n",
    "    \"        frame_count += 1\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    cap.release()\\n\",\n",
    "    \"    end_time = time.time()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Calculate metrics\\n\",\n",
    "    \"    processing_time = end_time - start_time\\n\",\n",
    "    \"    fps = frame_count / processing_time\\n\",\n",
    "    \"    total_detections = len(detections)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return {\\n\",\n",
    "    \"        'model': model_name,\\n\",\n",
    "    \"        'total_detections': total_detections,\\n\",\n",
    "    \"        'frames_processed': frame_count,\\n\",\n",
    "    \"        'processing_time': processing_time,\\n\",\n",
    "    \"        'fps': fps,\\n\",\n",
    "    \"        'detections_per_frame': total_detections / frame_count if frame_count > 0 else 0,\\n\",\n",
    "    \"        'detections': detections\\n\",\n",
    "    \"    }\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Test different models\\n\",\n",
    "    \"models_to_test = ['opencv', 'mtcnn', 'retinaface', 'yolo']\\n\",\n",
    "    \"results = []\\n\",\n",
    "    \"\\n\",\n",
    "    \"for model in models_to_test:\\n\",\n",
    "    \"    print(f\\\"Testing {model}...\\\")\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        result = evaluate_detection_model(model, video_path)\\n\",\n",
    "    \"        if result:\\n\",\n",
    "    \"            results.append(result)\\n\",\n",
    "    \"            print(f\\\"  FPS: {result['fps']:.2f}\\\")\\n\",\n",
    "    \"            print(f\\\"  Total detections: {result['total_detections']}\\\")\\n\",\n",
    "    \"    except Exception as e:\\n\",\n",
    "    \"        print(f\\\"  Error testing {model}: {e}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nCompleted testing {len(results)} models\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Results Visualization\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Create comparison plots\\n\",\n",
    "    \"if results:\\n\",\n",
    "    \"    models = [r['model'] for r in results]\\n\",\n",
    "    \"    fps_values = [r['fps'] for r in results]\\n\",\n",
    "    \"    detection_counts = [r['total_detections'] for r in results]\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # FPS comparison\\n\",\n",
    "    \"    ax1.bar(models, fps_values, color='skyblue')\\n\",\n",
    "    \"    ax1.set_title('Processing Speed (FPS)')\\n\",\n",
    "    \"    ax1.set_ylabel('Frames per Second')\\n\",\n",
    "    \"    ax1.tick_params(axis='x', rotation=45)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Detection count comparison\\n\",\n",
    "    \"    ax2.bar(models, detection_counts, color='lightcoral')\\n\",\n",
    "    \"    ax2.set_title('Total Detections')\\n\",\n",
    "    \"    ax2.set_ylabel('Number of Detections')\\n\",\n",
    "    \"    ax2.tick_params(axis='x', rotation=45)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.show()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Print detailed results\\n\",\n",
    "    \"    print(\\\"\\\\nDetailed Results:\\\")\\n\",\n",
    "    \"    print(\\\"-\\\" * 60)\\n\",\n",
    "    \"    for result in results:\\n\",\n",
    "    \"        print(f\\\"Model: {result['model']}\\\")\\n\",\n",
    "    \"        print(f\\\"  FPS: {result['fps']:.2f}\\\")\\n\",\n",
    "    \"        print(f\\\"  Total Detections: {result['total_detections']}\\\")\\n\",\n",
    "    \"        print(f\\\"  Detections/Frame: {result['detections_per_frame']:.2f}\\\")\\n\",\n",
    "    \"        print(f\\\"  Processing Time: {result['processing_time']:.2f}s\\\")\\n\",\n",
    "    \"        print()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Frame-by-Frame Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Analyze detection patterns over time\\n\",\n",
    "    \"if results:\\n\",\n",
    "    \"    best_model = max(results, key=lambda x: x['fps'])\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Group detections by frame\\n\",\n",
    "    \"    frame_detections = {}\\n\",\n",
    "    \"    for detection in best_model['detections']:\\n\",\n",
    "    \"        frame_idx = detection['frame_idx']\\n\",\n",
    "    \"        if frame_idx not in frame_detections:\\n\",\n",
    "    \"            frame_detections[frame_idx] = []\\n\",\n",
    "    \"        frame_detections[frame_idx].append(detection)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Plot detections over time\\n\",\n",
    "    \"    frames = sorted(frame_detections.keys())\\n\",\n",
    "    \"    detection_counts = [len(frame_detections[frame]) for frame in frames]\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.figure(figsize=(12, 6))\\n\",\n",
    "    \"    plt.plot(frames, detection_counts, 'b-', linewidth=2)\\n\",\n",
    "    \"    plt.title(f'Face Detections Over Time - {best_model[\\\"model\\\"]}')\\n\",\n",
    "    \"    plt.xlabel('Frame Number')\\n\",\n",
    "    \"    plt.ylabel('Number of Faces Detected')\\n\",\n",
    "    \"    plt.grid(True, alpha=0.3)\\n\",\n",
    "    \"    plt.show()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"Best performing model: {best_model['model']}\\\")\\n\",\n",
    "    \"    print(f\\\"Average faces per frame: {np.mean(detection_counts):.2f}\\\")\\n\",\n",
    "    \"    print(f\\\"Max faces in a frame: {max(detection_counts)}\\\")\\n\",\n",
    "    \"    print(f\\\"Min faces in a frame: {min(detection_counts)}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Confidence Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Analyze confidence distributions\\n\",\n",
    "    \"if results:\\n\",\n",
    "    \"    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\\n\",\n",
    "    \"    axes = axes.flatten()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for i, result in enumerate(results[:4]):  # Show up to 4 models\\n\",\n",
    "    \"        confidences = [d['confidence'] for d in result['detections']]\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        axes[i].hist(confidences, bins=20, alpha=0.7, color='steelblue')\\n\",\n",
    "    \"        axes[i].set_title(f'{result[\\\"model\\\"]} - Confidence Distribution')\\n\",\n",
    "    \"        axes[i].set_xlabel('Confidence Score')\\n\",\n",
    "    \"        axes[i].set_ylabel('Frequency')\\n\",\n",
    "    \"        axes[i].grid(True, alpha=0.3)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.show()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Print confidence statistics\\n\",\n",
    "    \"    print(\\\"\\\\nConfidence Statistics:\\\")\\n\",\n",
    "    \"    print(\\\"-\\\" * 40)\\n\",\n",
    "    \"    for result in results:\\n\",\n",
    "    \"        confidences = [d['confidence'] for d in result['detections']]\\n\",\n",
    "    \"        if confidences:\\n\",\n",
    "    \"            print(f\\\"{result['model']}:\\\")\\n\",\n",
    "    \"            print(f\\\"  Mean: {np.mean(confidences):.3f}\\\")\\n\",\n",
    "    \"            print(f\\\"  Std: {np.std(confidences):.3f}\\\")\\n\",\n",
    "    \"            print(f\\\"  Min: {min(confidences):.3f}\\\")\\n\",\n",
    "    \"            print(f\\\"  Max: {max(confidences):.3f}\\\")\\n\",\n",
    "    \"            print()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Save Results\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Save evaluation results\\n\",\n",
    "    \"if results:\\n\",\n",
    "    \"    output_path = Path('../data/outputs')\\n\",\n",
    "    \"    output_path.mkdir(parents=True, exist_ok=True)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Save summary results\\n\",\n",
    "    \"    summary_results = []\\n\",\n",
    "    \"    for result in results:\\n\",\n",
    "    \"        summary_results.append({\\n\",\n",
    "    \"            'model': result['model'],\\n\",\n",
    "    \"            'fps': result['fps'],\\n\",\n",
    "    \"            'total_detections': result['total_detections'],\\n\",\n",
    "    \"            'detections_per_frame': result['detections_per_frame'],\\n\",\n",
    "    \"            'processing_time': result['processing_time']\\n\",\n",
    "    \"        })\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    with open(output_path / 'detection_evaluation_results.json', 'w') as f:\\n\",\n",
    "    \"        json.dump(summary_results, f, indent=2)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"Results saved to {output_path / 'detection_evaluation_results.json'}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Save detailed detections for best model\\n\",\n",
    "    \"    best_model = max(results, key=lambda x: x['fps'])\\n\",\n",
    "    \"    with open(output_path / f'detections_{best_model[\\\"model\\\"]}.json', 'w') as f:\\n\",\n",
    "    \"        json.dump(best_model['detections'], f, indent=2)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"Detailed detections saved to {output_path / f'detections_{best_model['model']}.json'}\\\")\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.8.5\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
