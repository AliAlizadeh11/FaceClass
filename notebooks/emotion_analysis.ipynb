{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0814a9ec",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Emotion Analysis\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook analyzes facial expressions and emotions in classroom video data.\\n\",\n",
    "    \"\\n\",\n",
    "    \"## Features:\\n\",\n",
    "    \"- Emotion detection using various models\\n\",\n",
    "    \"- Attention analysis (gaze direction, head pose)\\n\",\n",
    "    \"- Temporal emotion patterns\\n\",\n",
    "    \"- Student engagement analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import sys\\n\",\n",
    "    \"sys.path.append('../src')\\n\",\n",
    "    \"\\n\",\n",
    "    \"import cv2\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"from pathlib import Path\\n\",\n",
    "    \"import json\\n\",\n",
    "    \"from collections import Counter\\n\",\n",
    "    \"\\n\",\n",
    "    \"from config import Config\\n\",\n",
    "    \"from detection.face_tracker import FaceTracker\\n\",\n",
    "    \"from emotion.emotion_detector import EmotionDetector\\n\",\n",
    "    \"from utils.video_utils import VideoProcessor\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Load configuration and initialize components\\n\",\n",
    "    \"config = Config()\\n\",\n",
    "    \"video_processor = VideoProcessor(config)\\n\",\n",
    "    \"face_tracker = FaceTracker(config)\\n\",\n",
    "    \"emotion_detector = EmotionDetector(config)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Test video path\\n\",\n",
    "    \"video_path = \\\"../data/raw_videos/sample_classroom.mp4\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Components initialized\\\")\\n\",\n",
    "    \"print(f\\\"Video path: {video_path}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Emotion Detection Pipeline\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def process_video_emotions(video_path, max_frames=200):\\n\",\n",
    "    \"    \\\"\\\"\\\"Process video and extract emotion data.\\\"\\\"\\\"\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    cap = cv2.VideoCapture(video_path)\\n\",\n",
    "    \"    if not cap.isOpened():\\n\",\n",
    "    \"        print(f\\\"Failed to open video: {video_path}\\\")\\n\",\n",
    "    \"        return []\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    all_detections = []\\n\",\n",
    "    \"    frame_idx = 0\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    while frame_idx < max_frames:\\n\",\n",
    "    \"        ret, frame = cap.read()\\n\",\n",
    "    \"        if not ret:\\n\",\n",
    "    \"            break\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Detect faces\\n\",\n",
    "    \"        face_detections = face_tracker.detect_faces(frame)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Process each face for emotions\\n\",\n",
    "    \"        for detection in face_detections:\\n\",\n",
    "    \"            bbox = detection['bbox']\\n\",\n",
    "    \"            x1, y1, x2, y2 = bbox\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            # Extract face region\\n\",\n",
    "    \"            face_region = frame[y1:y2, x1:x2]\\n\",\n",
    "    \"            if face_region.size == 0:\\n\",\n",
    "    \"                continue\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            # Detect emotions\\n\",\n",
    "    \"            emotions = emotion_detector.detect_emotions(face_region)\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            # Detect attention\\n\",\n",
    "    \"            attention = emotion_detector.detect_attention(face_region)\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            # Add to detection\\n\",\n",
    "    \"            detection.update({\\n\",\n",
    "    \"                'frame_idx': frame_idx,\\n\",\n",
    "    \"                'emotions': emotions,\\n\",\n",
    "    \"                'attention': attention,\\n\",\n",
    "    \"                'dominant_emotion': max(emotions.items(), key=lambda x: x[1])[0],\\n\",\n",
    "    \"                'emotion_confidence': max(emotions.values()),\\n\",\n",
    "    \"                'is_attentive': attention['attention_score'] > 0.7\\n\",\n",
    "    \"            })\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            all_detections.append(detection)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        frame_idx += 1\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        if frame_idx % 50 == 0:\\n\",\n",
    "    \"            print(f\\\"Processed {frame_idx} frames\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    cap.release()\\n\",\n",
    "    \"    print(f\\\"Completed processing {len(all_detections)} detections\\\")\\n\",\n",
    "    \"    return all_detections\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Process video for emotion analysis\\n\",\n",
    "    \"detections = process_video_emotions(video_path)\\n\",\n",
    "    \"\\n\",\n",
    "    \"if detections:\\n\",\n",
    "    \"    print(f\\\"\\\\nProcessed {len(detections)} face detections\\\")\\n\",\n",
    "    \"    print(f\\\"Frames analyzed: {max(d['frame_idx'] for d in detections) + 1}\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"No detections found\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Emotion Distribution Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"if detections:\\n\",\n",
    "    \"    # Extract emotion data\\n\",\n",
    "    \"    emotions = [d['dominant_emotion'] for d in detections]\\n\",\n",
    "    \"    emotion_counts = Counter(emotions)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Create emotion distribution plot\\n\",\n",
    "    \"    plt.figure(figsize=(12, 6))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Bar chart\\n\",\n",
    "    \"    plt.subplot(1, 2, 1)\\n\",\n",
    "    \"    emotion_names = list(emotion_counts.keys())\\n\",\n",
    "    \"    emotion_values = list(emotion_counts.values())\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    colors = plt.cm.Set3(np.linspace(0, 1, len(emotion_names)))\\n\",\n",
    "    \"    bars = plt.bar(emotion_names, emotion_values, color=colors)\\n\",\n",
    "    \"    plt.title('Emotion Distribution')\\n\",\n",
    "    \"    plt.xlabel('Emotion')\\n\",\n",
    "    \"    plt.ylabel('Count')\\n\",\n",
    "    \"    plt.xticks(rotation=45)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Add value labels on bars\\n\",\n",
    "    \"    for bar, value in zip(bars, emotion_values):\\n\",\n",
    "    \"        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, \\n\",\n",
    "    \"                str(value), ha='center', va='bottom')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Pie chart\\n\",\n",
    "    \"    plt.subplot(1, 2, 2)\\n\",\n",
    "    \"    plt.pie(emotion_values, labels=emotion_names, autopct='%1.1f%%', colors=colors)\\n\",\n",
    "    \"    plt.title('Emotion Distribution (%)')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.show()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Print statistics\\n\",\n",
    "    \"    print(\\\"\\\\nEmotion Statistics:\\\")\\n\",\n",
    "    \"    print(\\\"-\\\" * 30)\\n\",\n",
    "    \"    for emotion, count in emotion_counts.most_common():\\n\",\n",
    "    \"        percentage = (count / len(emotions)) * 100\\n\",\n",
    "    \"        print(f\\\"{emotion.title()}: {count} ({percentage:.1f}%)\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Attention Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"if detections:\\n\",\n",
    "    \"    # Extract attention data\\n\",\n",
    "    \"    attention_scores = [d['attention']['attention_score'] for d in detections]\\n\",\n",
    "    \"    head_poses_x = [d['attention']['head_pose_x'] for d in detections]\\n\",\n",
    "    \"    head_poses_y = [d['attention']['head_pose_y'] for d in detections]\\n\",\n",
    "    \"    gaze_x = [d['attention']['gaze_x'] for d in detections]\\n\",\n",
    "    \"    gaze_y = [d['attention']['gaze_y'] for d in detections]\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Create attention analysis plots\\n\",\n",
    "    \"    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Attention score distribution\\n\",\n",
    "    \"    axes[0, 0].hist(attention_scores, bins=20, alpha=0.7, color='skyblue')\\n\",\n",
    "    \"    axes[0, 0].set_title('Attention Score Distribution')\\n\",\n",
    "    \"    axes[0, 0].set_xlabel('Attention Score')\\n\",\n",
    "    \"    axes[0, 0].set_ylabel('Frequency')\\n\",\n",
    "    \"    axes[0, 0].axvline(np.mean(attention_scores), color='red', linestyle='--', \\n\",\n",
    "    \"                       label=f'Mean: {np.mean(attention_scores):.3f}')\\n\",\n",
    "    \"    axes[0, 0].legend()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Head pose analysis\\n\",\n",
    "    \"    axes[0, 1].scatter(head_poses_x, head_poses_y, alpha=0.6, c=attention_scores, cmap='RdYlGn')\\n\",\n",
    "    \"    axes[0, 1].set_title('Head Pose vs Attention')\\n\",\n",
    "    \"    axes[0, 1].set_xlabel('Head Pose X (degrees)')\\n\",\n",
    "    \"    axes[0, 1].set_ylabel('Head Pose Y (degrees)')\\n\",\n",
    "    \"    axes[0, 1].grid(True, alpha=0.3)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Gaze direction\\n\",\n",
    "    \"    axes[1, 0].scatter(gaze_x, gaze_y, alpha=0.6, c=attention_scores, cmap='RdYlGn')\\n\",\n",
    "    \"    axes[1, 0].set_title('Gaze Direction vs Attention')\\n\",\n",
    "    \"    axes[1, 0].set_xlabel('Gaze X')\\n\",\n",
    "    \"    axes[1, 0].set_ylabel('Gaze Y')\\n\",\n",
    "    \"    axes[1, 0].grid(True, alpha=0.3)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Attention over time\\n\",\n",
    "    \"    frame_indices = [d['frame_idx'] for d in detections]\\n\",\n",
    "    \"    axes[1, 1].scatter(frame_indices, attention_scores, alpha=0.6, c=attention_scores, cmap='RdYlGn')\\n\",\n",
    "    \"    axes[1, 1].set_title('Attention Over Time')\\n\",\n",
    "    \"    axes[1, 1].set_xlabel('Frame Number')\\n\",\n",
    "    \"    axes[1, 1].set_ylabel('Attention Score')\\n\",\n",
    "    \"    axes[1, 1].grid(True, alpha=0.3)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.show()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Print attention statistics\\n\",\n",
    "    \"    print(\\\"\\\\nAttention Statistics:\\\")\\n\",\n",
    "    \"    print(\\\"-\\\" * 30)\\n\",\n",
    "    \"    print(f\\\"Average attention score: {np.mean(attention_scores):.3f}\\\")\\n\",\n",
    "    \"    print(f\\\"Attention score std: {np.std(attention_scores):.3f}\\\")\\n\",\n",
    "    \"    print(f\\\"High attention (>0.7): {sum(1 for s in attention_scores if s > 0.7)} ({sum(1 for s in attention_scores if s > 0.7)/len(attention_scores)*100:.1f}%)\\\")\\n\",\n",
    "    \"    print(f\\\"Low attention (<0.3): {sum(1 for s in attention_scores if s < 0.3)} ({sum(1 for s in attention_scores if s < 0.3)/len(attention_scores)*100:.1f}%)\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Temporal Emotion Patterns\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"if detections:\\n\",\n",
    "    \"    # Create time series data\\n\",\n",
    "    \"    df = pd.DataFrame(detections)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Group by frame and calculate statistics\\n\",\n",
    "    \"    frame_stats = df.groupby('frame_idx').agg({\\n\",\n",
    "    \"        'attention': lambda x: np.mean([d['attention_score'] for d in x]),\\n\",\n",
    "    \"        'emotion_confidence': 'mean',\\n\",\n",
    "    \"        'dominant_emotion': lambda x: x.mode().iloc[0] if not x.mode().empty else 'neutral'\\n\",\n",
    "    \"    }).reset_index()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Plot temporal patterns\\n\",\n",
    "    \"    fig, axes = plt.subplots(2, 1, figsize=(15, 10))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Attention over time\\n\",\n",
    "    \"    axes[0].plot(frame_stats['frame_idx'], frame_stats['attention'], 'b-', linewidth=2)\\n\",\n",
    "    \"    axes[0].set_title('Average Attention Over Time')\\n\",\n",
    "    \"    axes[0].set_xlabel('Frame Number')\\n\",\n",
    "    \"    axes[0].set_ylabel('Average Attention Score')\\n\",\n",
    "    \"    axes[0].grid(True, alpha=0.3)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Emotion confidence over time\\n\",\n",
    "    \"    axes[1].plot(frame_stats['frame_idx'], frame_stats['emotion_confidence'], 'g-', linewidth=2)\\n\",\n",
    "    \"    axes[1].set_title('Emotion Confidence Over Time')\\n\",\n",
    "    \"    axes[1].set_xlabel('Frame Number')\\n\",\n",
    "    \"    axes[1].set_ylabel('Average Emotion Confidence')\\n\",\n",
    "    \"    axes[1].grid(True, alpha=0.3)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.show()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Emotion transitions\\n\",\n",
    "    \"    emotion_sequence = frame_stats['dominant_emotion'].tolist()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Create emotion transition matrix\\n\",\n",
    "    \"    emotions = list(set(emotion_sequence))\\n\",\n",
    "    \"    transition_matrix = np.zeros((len(emotions), len(emotions)))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for i in range(len(emotion_sequence) - 1):\\n\",\n",
    "    \"        current_idx = emotions.index(emotion_sequence[i])\\n\",\n",
    "    \"        next_idx = emotions.index(emotion_sequence[i + 1])\\n\",\n",
    "    \"        transition_matrix[current_idx, next_idx] += 1\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Normalize\\n\",\n",
    "    \"    row_sums = transition_matrix.sum(axis=1)\\n\",\n",
    "    \"    transition_matrix = transition_matrix / row_sums[:, np.newaxis]\\n\",\n",
    "    \"    transition_matrix = np.nan_to_num(transition_matrix)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Plot transition matrix\\n\",\n",
    "    \"    plt.figure(figsize=(10, 8))\\n\",\n",
    "    \"    sns.heatmap(transition_matrix, annot=True, fmt='.2f', \\n\",\n",
    "    \"                xticklabels=emotions, yticklabels=emotions, cmap='Blues')\\n\",\n",
    "    \"    plt.title('Emotion Transition Matrix')\\n\",\n",
    "    \"    plt.xlabel('Next Emotion')\\n\",\n",
    "    \"    plt.ylabel('Current Emotion')\\n\",\n",
    "    \"    plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Student Engagement Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"if detections:\\n\",\n",
    "    \"    # Analyze engagement patterns\\n\",\n",
    "    \"    engagement_data = []\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for detection in detections:\\n\",\n",
    "    \"        attention = detection['attention']['attention_score']\\n\",\n",
    "    \"        emotion = detection['dominant_emotion']\\n\",\n",
    "    \"        confidence = detection['emotion_confidence']\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Define engagement score\\n\",\n",
    "    \"        engagement_score = attention * confidence\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Categorize engagement level\\n\",\n",
    "    \"        if engagement_score > 0.7:\\n\",\n",
    "    \"            engagement_level = 'High'\\n\",\n",
    "    \"        elif engagement_score > 0.4:\\n\",\n",
    "    \"            engagement_level = 'Medium'\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            engagement_level = 'Low'\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        engagement_data.append({\\n\",\n",
    "    \"            'frame_idx': detection['frame_idx'],\\n\",\n",
    "    \"            'attention': attention,\\n\",\n",
    "    \"            'emotion': emotion,\\n\",\n",
    "    \"            'confidence': confidence,\\n\",\n",
    "    \"            'engagement_score': engagement_score,\\n\",\n",
    "    \"            'engagement_level': engagement_level\\n\",\n",
    "    \"        })\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Create engagement analysis\\n\",\n",
    "    \"    engagement_df = pd.DataFrame(engagement_data)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Engagement distribution\\n\",\n",
    "    \"    plt.figure(figsize=(15, 5))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.subplot(1, 3, 1)\\n\",\n",
    "    \"    engagement_levels = engagement_df['engagement_level'].value_counts()\\n\",\n",
    "    \"    colors = ['red', 'orange', 'green']\\n\",\n",
    "    \"    plt.pie(engagement_levels.values, labels=engagement_levels.index, autopct='%1.1f%%', colors=colors)\\n\",\n",
    "    \"    plt.title('Engagement Level Distribution')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.subplot(1, 3, 2)\\n\",\n",
    "    \"    plt.hist(engagement_df['engagement_score'], bins=20, alpha=0.7, color='purple')\\n\",\n",
    "    \"    plt.title('Engagement Score Distribution')\\n\",\n",
    "    \"    plt.xlabel('Engagement Score')\\n\",\n",
    "    \"    plt.ylabel('Frequency')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.subplot(1, 3, 3)\\n\",\n",
    "    \"    engagement_by_emotion = engagement_df.groupby('emotion')['engagement_score'].mean().sort_values(ascending=False)\\n\",\n",
    "    \"    engagement_by_emotion.plot(kind='bar', color='lightblue')\\n\",\n",
    "    \"    plt.title('Average Engagement by Emotion')\\n\",\n",
    "    \"    plt.xlabel('Emotion')\\n\",\n",
    "    \"    plt.ylabel('Average Engagement Score')\\n\",\n",
    "    \"    plt.xticks(rotation=45)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.show()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Print engagement statistics\\n\",\n",
    "    \"    print(\\\"\\\\nEngagement Analysis:\\\")\\n\",\n",
    "    \"    print(\\\"-\\\" * 30)\\n\",\n",
    "    \"    print(f\\\"Average engagement score: {engagement_df['engagement_score'].mean():.3f}\\\")\\n\",\n",
    "    \"    print(f\\\"Engagement score std: {engagement_df['engagement_score'].std():.3f}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(\\\"\\\\nEngagement by level:\\\")\\n\",\n",
    "    \"    for level, count in engagement_levels.items():\\n\",\n",
    "    \"        percentage = (count / len(engagement_df)) * 100\\n\",\n",
    "    \"        print(f\\\"  {level}: {count} ({percentage:.1f}%)\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(\\\"\\\\nEngagement by emotion:\\\")\\n\",\n",
    "    \"    for emotion, score in engagement_by_emotion.items():\\n\",\n",
    "    \"        print(f\\\"  {emotion.title()}: {score:.3f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Save Analysis Results\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Save analysis results\\n\",\n",
    "    \"if detections:\\n\",\n",
    "    \"    output_path = Path('../data/outputs')\\n\",\n",
    "    \"    output_path.mkdir(parents=True, exist_ok=True)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Save raw detection data\\n\",\n",
    "    \"    with open(output_path / 'emotion_analysis_results.json', 'w') as f:\\n\",\n",
    "    \"        json.dump(detections, f, indent=2, default=str)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Save summary statistics\\n\",\n",
    "    \"    summary = {\\n\",\n",
    "    \"        'total_detections': len(detections),\\n\",\n",
    "    \"        'frames_analyzed': max(d['frame_idx'] for d in detections) + 1,\\n\",\n",
    "    \"        'emotion_distribution': dict(Counter(d['dominant_emotion'] for d in detections)),\\n\",\n",
    "    \"        'average_attention': np.mean([d['attention']['attention_score'] for d in detections]),\\n\",\n",
    "    \"        'average_emotion_confidence': np.mean([d['emotion_confidence'] for d in detections]),\\n\",\n",
    "    \"        'engagement_levels': dict(engagement_levels) if 'engagement_levels' in locals() else {}\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    with open(output_path / 'emotion_analysis_summary.json', 'w') as f:\\n\",\n",
    "    \"        json.dump(summary, f, indent=2)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"Analysis results saved to {output_path}\\\")\\n\",\n",
    "    \"    print(f\\\"  - Raw data: emotion_analysis_results.json\\\")\\n\",\n",
    "    \"    print(f\\\"  - Summary: emotion_analysis_summary.json\\\")\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.8.5\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
